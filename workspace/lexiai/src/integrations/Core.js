export async function UploadFile({ file }) {
  // In browser: create object URL to simulate an uploaded file URL
  const file_url = URL.createObjectURL(file)
  return { file_url }
}

export async function ExtractDataFromUploadedFile({ file_url, json_schema }) {
  // Mock extracted content
  return {
    status: 'success',
    output: {
      content: `Extracted content for ${file_url}. (Mocked)`
    }
  }
}

export async function InvokeLLM({ prompt, add_context_from_internet = false, response_json_schema }) {
  // Very simple heuristic mock to satisfy both Chat and CreateCase flows
  if (response_json_schema && response_json_schema.type === 'object') {
    // CreateCase expects a case-shaped object
    const lower = prompt.toLowerCase()
    const guessType = lower.includes('contract') ? 'contract_dispute' : lower.includes('injury') ? 'personal_injury' : 'other'
    const title = (prompt.match(/title:\s*(.*)/i)?.[1] || 'New Legal Case').trim()
    return {
      // Chat flow expects these when schema includes them
      response_text: 'Here is an initial analysis based on your case details. (Mocked AI response)',
      jurisdiction_analysis: undefined,
      updated_case_data: undefined,
      // CreateCase fields (extra keys will be ignored by code that doesn't need them)
      title,
      case_type: guessType,
      description: 'Structured summary generated by AI (mock).',
      jurisdiction: 'Unknown',
      priority: 'medium',
      deadline: undefined,
    }
  }

  // Generator expects a string
  return `Generated legal document (mock):\n\n${prompt.substring(0, 400)}...`
}